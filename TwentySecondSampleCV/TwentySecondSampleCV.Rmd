---
name: "Aritra"
surname: "Chatterjee"
position: "Sr.DataEngineering Analyst"
address: "Flat 403, Udaya Abhi's Residency, Kondapur, Hyderabad."
phone: +91 8017781327
profilepic: Aritra.jpg
email: "richie.chatterjee31@gmail.com"
github: richie312
date: "`r format(Sys.time(), '%B %Y')`"
aboutme: "A professional in the field of Machine Learning, API Development, Data Engineering and Devops with more than 10 years of experience."
output: vitae::twentyseconds
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(vitae)
```

# Domain wise skill set

```{r}
library(tibble)
tribble(
  ~Domain, ~Skill,
  "Languages", "Python,R,Javascript,HTML,Markdown.",
  "Database", "SQL,MySQL,PostgreSQL,Teradata.",
  "WebApplicationFramework", "Flask|Swagger(Python|API Dev).",
  "Cloud",  "Glue,EC2,S3,ECS,ECR,SNS,lambda,CloudWatch,Kafka",
  "Devops", "Jenkins,Docker,Openshift, Kubernetes.",
  "Orchestrator", "Databricks, Airflow"
) %>% 
  detailed_entries(
    Domain,
    Skill
  )
```

# Experience

```{r}
library(tibble)
tribble(
  ~ Company, ~ Year, ~ Skills, ~ Description,
  "Accenture", "2022- Present","DataEngineering & Work Automation","Cobol to python migration, scheduling jobs using databricks. Work Automation using pipeline to update the databricks json, gcs bucket and other infrastructure related documents for end 2 end executuion of pipeine. Use of yml files to write CI|CD pipelines.",
  
  "Accenture", "2021- Present","DataEngineering","Sas to Python Migration,IRB Document Integration using python, Data Modelling & Dataquality using pyspark. AWS Lambda Deployment, Jenkins Pipeline, AWS Route 53, Spark Transformations along with Kafka|AWS Kinesis.",
  "Larsen & Toubro Infotech(S&P Global)", "2020-2021", "DataEngineering", "Planned, designed and implemented automated framework which takes json template as an input and applies spark transformation on dataset to generate the report in json which finally feeds the predefined tableau dashboard.",
  "CapitalNumbers Infotech", "2019-2020", "APIDevelopment", "Implemented Online Compiler for 14 different languages using sphere engine api, api creation (flask).",
  "GSPANN Technologies", "2019", "AWS|DataEngineering", "Build Data Pipeline for Google Analytics for client web application. Aws automation using boto3 with Python.",
  "Colt India Pvt. Ltd","2018", "R|MachineLearning", "Customer Churn management. Visualisation using leaflet and network graph.",
  "Accenture India", "2012-2017","R|Python|ML|NLP", "Data Science",
  "IBM GPS India","2011-2012", "ITIL", "Incident, Change and Problem Management."
) %>% 
  detailed_entries( Company, Year, Skills, Description)
```

# Education

```{r}
library(tibble)
tribble(
  ~Degree,~Subject,~Year,~Institution,
  "Secondary","Standard", "2001","KV2 Kalaikunda,WB",
  "HigherSecondary","PCMB", "2003","KV1 SaltLake,Kolkata",
  "Graduation","Economics(Honors) Maths,Stats","2006","Siliguri College, WB",
  "PostGraduation","Marketing|MIS", "2009","GBS,Kolkata"
) %>% 
  detailed_entries(
   Degree,Subject,Year,Institution
  )
```